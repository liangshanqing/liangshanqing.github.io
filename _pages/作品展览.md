---
layout: page
title: 作品展览
permalink: /workgallery/
image: 01.jpg
---

个人能力总结

***

### 研究能力

在实习经历中，我曾做过比较成体系的行业研究和公司研究，形成了自己比较完善的行研SOP，能够较为快速地了解一个新行业，并且在日常也会常看商业新闻持续累积商业sense。我参与过家电、折扣零售、出海、电商、运动健身、保健药品、二次元手办、AI Infra等消费类行业和AI Infra、AI电力等AI行业的研究。总体来说，消费行业作为一个需求驱动的行业，未来需要不断发现市场新需求在哪里，并且通过新渠道可以触达更多的需求；而AI行业作为一个技术驱动的行业，目前还处在方兴未艾的阶段，未来行业增长空间目前还看不到上限，不过可能比行业规模更需要思考的是，未来人类世代会走向何方。

下面是我写过的一些报告，供参考：


* <strong>某清洁电器上游产业链公司深度报告</strong>


<body>
    <!-- 展示区域 -->
    <main class="cleaner-report">
        <!-- 预览区域 -->
        <section class="report-preview">
            <iframe src="/assets/春光科技（603657）深度 240129.pdf" width="100%" height="600px" style="border: none;"></iframe>
        </section>
    </main>
</body>


* <strong>某黑马洗地机公司出海报告</strong>


<body>
    <!-- 展示区域 -->
    <main class="cleaner-report">
        <!-- 预览区域 -->
        <section class="report-preview">
            <iframe src="/assets/追觅出海梳理231208.pdf" width="100%" height="600px" style="border: none;"></iframe>
        </section>
    </main>
</body>


* <strong>AI Infra研究报告</strong>


<body>
    <!-- 展示区域 -->
    <main class="cleaner-report">
        <!-- 预览区域 -->
        <section class="report-preview">
            <iframe src="/assets/AI Infra研究报告.pdf" width="100%" height="600px" style="border: none;"></iframe>
        </section>
    </main>
    <style>
        .pdf-viewer {
            width: 100%;
            height: 100%;
            border: none;
        }
    </style>
</body>


* <strong>AI电力研究报告</strong>


<body>
    <!-- 展示区域 -->
    <main class="cleaner-report">
        <!-- 预览区域 -->
        <section class="report-preview">
            <iframe src="/assets/AI电力研究报告.pdf" width="100%" height="600px" style="border: none;"></iframe>
        </section>
    </main>
    <style>
        .pdf-viewer {
            width: 100%;
            height: 100%;
            border: none;
        }
    </style>
</body>

---
### 编程能力

作为一名经济金融专业的学生，数据分析是我的必备技能。我较为熟悉的数据分析工具有：
* <strong>Microsoft Excel：</strong>熟悉基础快捷键，会用vlookup、sumif、countif等基础函数，以及数据透视表辅助分析。
* <strong>Python：</strong>基础数据处理、交易策略等。
* <strong>Stata：</strong>经济理论必备。
* 目前也在自学SQL和Tableau。

下面是我用Python进行<strong>基础数据处理</strong>和<strong>选股策略、大宗商品carry策略</strong>的展示：

* 基础数据处理：

```python
print("hi")
```

* 基于XGBoost的机器学习选股策略：

```python
import pandas as pd
import numpy as np
import time
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties
from sklearn.decomposition import PCA
from factor_analyzer import FactorAnalyzer, calculate_kmo
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score
from rqalpha.apis import *

# 设置中文字体
font = FontProperties(fname='C:/Windows/Fonts/simhei.ttf')

# Start the timer
start_time = time.time()

#%% 读取数据
# Read the financial_final.csv file with specified encoding
csv_file_path = 'input\财务数据\financial_final.csv'
financial_final_data = pd.read_csv(csv_file_path, encoding='gbk')
print(financial_final_data)

#%% 主成分分解
# Select the columns for PCA
pca_columns = financial_final_data.loc[:, 'std_F010101A_epo':'std_F092101C_epo']

# Plot the correlation heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(pca_columns.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Heatmap', fontproperties=font)
plt.savefig('output\\graph\\correlation_heatmap.png')
plt.show()

# Perform the KMO test
kmo_all, kmo_model = calculate_kmo(pca_columns)
print(f"KMO Test: {kmo_model}")

# Perform PCA
pca = PCA()
pca.fit(pca_columns)

# Determine the optimal number of components to retain 80% variance
cumulative_variance = np.cumsum(pca.explained_variance_ratio_)
optimal_components = np.argmax(cumulative_variance >= 0.8) + 1
print(f"Optimal number of components to retain 80% variance: {optimal_components}")

# Perform PCA with the optimal number of components
pca_optimal = PCA(n_components=optimal_components)
pca_optimal.fit(pca_columns)

# Transform the original features using the PCA model
pca_features = pca_optimal.transform(pca_columns)

# Plot the cumulative variance contribution
plt.figure(figsize=(10, 6))
plt.plot(cumulative_variance)
plt.axhline(y=0.8, color='r', linestyle='--')
plt.axvline(x=optimal_components - 1, color='r', linestyle='--')
plt.xlabel('Number of Components', fontproperties=font)
plt.ylabel('Cumulative Explained Variance', fontproperties=font)
plt.title('Cumulative Variance Contribution', fontproperties=font)
plt.grid(True)
plt.savefig('output\\graph\\cumulative_variance_contribution.png')
plt.show()

# Plot the scree plot
plt.figure(figsize=(10, 6))
plt.plot(range(1, len(pca.explained_variance_) + 1), pca.explained_variance_, marker='o')
plt.axvline(x=optimal_components, color='r', linestyle='--')
plt.xlabel('Number of Components', fontproperties=font)
plt.ylabel('Eigenvalue', fontproperties=font)
plt.title('Scree Plot', fontproperties=font)
plt.grid(True)
plt.savefig('output\\graph\\scree_plot.png')
plt.show()

# Output the principal component loading matrix
loadings = pd.DataFrame(pca_optimal.components_.T, columns=[f'PC{i+1}' for i in range(optimal_components)], index=pca_columns.columns)
print("Principal Component Loading Matrix:")
print(loadings)

# Save the principal component loading matrix to a CSV file
loadings.to_csv('output\\table\\principal_component_loading_matrix.csv')

# Plot the heatmap of the principal component loading matrix
plt.figure(figsize=(12, 10))
sns.heatmap(loadings, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Principal Component Loading Matrix Heatmap', fontproperties=font)
plt.savefig('output\\graph\\principal_component_loading_matrix_heatmap.png')
plt.show()

#%% 计算标签
# Ensure the date column is in datetime format
financial_final_data['date'] = pd.to_datetime(financial_final_data['date'])

# Sort the data by 'code' and 'date'
financial_final_data = financial_final_data.sort_values(by=['code', 'date'])

# Calculate the monthly return
financial_final_data['next_month_close'] = financial_final_data.groupby('code')['close'].shift(-1)
financial_final_data['monthly_return'] = (financial_final_data['next_month_close'] / financial_final_data['close']) - 1

# Drop rows where next_month_close is NaN (i.e., the last month for each stock)
financial_final_data = financial_final_data.dropna(subset=['next_month_close'])

print(financial_final_data[['code', 'date', 'close', 'next_month_close', 'monthly_return']])

#%% 训练模型
# Filter data for training (2010-2021) and prediction (2022-2024)
train_data = financial_final_data[(financial_final_data['date'].dt.year >= 2010) & (financial_final_data['date'].dt.year <= 2021)]
predict_data = financial_final_data[(financial_final_data['date'].dt.year >= 2022) & (financial_final_data['date'].dt.year <= 2024)]

# Select the columns for the model
features = train_data.loc[:, 'std_F010101A_epo':'std_F092101C_epo']
target = train_data['monthly_return']

# Transform the features using the PCA model
pca_features_train = pca_optimal.transform(features)
pca_features_predict = pca_optimal.transform(predict_data.loc[:, 'std_F010101A_epo':'std_F092101C_epo'])

# Split the data into training and testing sets (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(pca_features_train, target, test_size=0.2, random_state=42)

# Train an XGBoost model
xgb_model = xgb.XGBRegressor(n_estimators=100, random_state=42)
xgb_model.fit(X_train, y_train)

# Evaluate the model on the test set
y_pred = xgb_model.predict(X_test)
print(f"Mean Squared Error: {mean_squared_error(y_test, y_pred)}")

# Calculate accuracy, precision, and recall for the training dataset
y_train_pred = xgb_model.predict(X_train)
y_train_sign = np.sign(y_train)
y_train_pred_sign = np.sign(y_train_pred)

accuracy = accuracy_score(y_train_sign, y_train_pred_sign)
precision = precision_score(y_train_sign, y_train_pred_sign, average='macro')
recall = recall_score(y_train_sign, y_train_pred_sign, average='macro')

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

# Add grouping labels to the training dataset
train_data['group'] = train_data.groupby('date')['monthly_return'].transform(
    lambda x: pd.qcut(x, 10, labels=False, duplicates='drop')
)

# Predict the next month's return for samples between 2022 and 2024
predict_data['monthly_return_predict'] = xgb_model.predict(pca_features_predict)

# Group the predicted returns for each date
predict_data['group'] = predict_data.groupby('date')['monthly_return_predict'].transform(
    lambda x: pd.qcut(x, 10, labels=False, duplicates='drop')
)

#%% 构建策略所需的数据
# Label the top 100 stocks in groups 9 and 0
predict_data['label'] = 0
for date, group in predict_data.groupby('date'):
    top_100_group_9 = group[group['group'] == 9].nlargest(100, 'monthly_return_predict')
    top_100_group_0 = group[group['group'] == 0].nsmallest(100, 'monthly_return_predict')
    predict_data.loc[top_100_group_9.index, 'label'] = 1
    predict_data.loc[top_100_group_0.index, 'label'] = -1

# Calculate accuracy, precision, and recall for groups 9 and 0
group_9_data = predict_data[predict_data['group'] == 9]
group_0_data = predict_data[predict_data['group'] == 0]

group_9_accuracy = accuracy_score(group_9_data['monthly_return'] > 0, group_9_data['monthly_return_predict'] > 0)
group_0_accuracy = accuracy_score(group_0_data['monthly_return'] < 0, group_0_data['monthly_return_predict'] < 0)

group_9_precision = precision_score(group_9_data['monthly_return'] > 0, group_9_data['monthly_return_predict'] > 0, average='macro')
group_0_precision = precision_score(group_0_data['monthly_return'] < 0, group_0_data['monthly_return_predict'] < 0, average='macro')

group_9_recall = recall_score(group_9_data['monthly_return'] > 0, group_9_data['monthly_return_predict'] > 0, average='macro')
group_0_recall = recall_score(group_0_data['monthly_return'] < 0, group_0_data['monthly_return_predict'] < 0, average='macro')

print(f"Group 9 - Accuracy: {group_9_accuracy}, Precision: {group_9_precision}, Recall: {group_9_recall}")
print(f"Group 0 - Accuracy: {group_0_accuracy}, Precision: {group_0_precision}, Recall: {group_0_recall}")

print(predict_data[['code', 'date', 'monthly_return', 'monthly_return_predict', 'group', 'label']])

# Calculate average next month's return and standard deviation for each decile group
group_stats = predict_data.groupby('group')['monthly_return'].agg(['mean', 'std']).reset_index()

# Plot the combination chart
fig, ax1 = plt.subplots(figsize=(12, 8))

# Bar chart for average next month's return
ax1.bar(group_stats['group'], group_stats['mean'], color='b', alpha=0.6, label='Average Monthly Return')
ax1.set_xlabel('Decile Group', fontproperties=font)
ax1.set_ylabel('Average Monthly Return', fontproperties=font)
ax1.tick_params(axis='y', labelcolor='b')

# Line chart for standard deviation of next month's return
ax2 = ax1.twinx()
ax2.plot(group_stats['group'], group_stats['std'], color='r', marker='o', label='Standard Deviation')
ax2.set_ylabel('Standard Deviation', fontproperties=font)
ax2.tick_params(axis='y', labelcolor='r')

# Add legends
fig.legend(loc='upper right', bbox_to_anchor=(1,1), bbox_transform=ax1.transAxes)

plt.title('Average Monthly Return and Standard Deviation by Decile Group', fontproperties=font)

# Save the plot as an image file
plt.savefig('output\\graph\\average_monthly_return_and_std_by_decile_group_PCA_xgboost.png')

plt.show()

# Save the prediction results to a CSV file without financial factors and ensure no Chinese characters are garbled
output_file_path = 'output\\table\\financial_data_with_return_predictions_xgboost_ret_PCA.csv'
predict_data[['code', 'date',  'monthly_return', 'monthly_return_predict', 'group', 'label']].to_csv(output_file_path, index=False, encoding='utf-8-sig')

# End the timer and print the elapsed time
end_time = time.time()
elapsed_time = end_time - start_time
print(f"Elapsed time: {elapsed_time} seconds")

#%% 评估选股风格

# 评估每个组别最偏好的行业
industry_preference = predict_data.groupby('group')['first_industry_name'].agg(lambda x: x.value_counts().idxmax())
print("每个组别最偏好的行业：")
print(industry_preference)

# 评估每个组别的平均市值
average_size = predict_data.groupby('group')['size'].mean()
print("每个组别的平均市值：")
print(average_size)

# 评估每个组别的平均收益率
average_return = predict_data.groupby('group')['monthly_return'].mean()
print("每个组别的平均收益率：")
print(average_return)

# 评估每个组别的波动率（收益率的标准差）
volatility = predict_data.groupby('group')['monthly_return'].std()
print("每个组别的波动率：")
print(volatility)

# 计算标准化行业偏好
industry_counts = predict_data.groupby(['group', 'first_industry_name']).size().unstack().fillna(0)
total_industry_counts = predict_data['first_industry_name'].value_counts()
standardized_industry_preference = industry_counts.div(total_industry_counts, axis=1)

# 可视化标准化行业偏好
plt.figure(figsize=(12, 8))
standardized_industry_preference.plot(kind='bar', stacked=True, colormap='tab20', figsize=(12, 8))
plt.title('Standardized Industry Preference by Group', fontproperties=font)
plt.xlabel('Group', fontproperties=font)
plt.ylabel('Standardized Preference', fontproperties=font)
plt.xticks(rotation=0)
plt.legend(title='Industry', bbox_to_anchor=(1.05, 1), loc='upper left', prop=font)

# 添加标签
for i in range(len(standardized_industry_preference)):
    max_industry = standardized_industry_preference.iloc[i].idxmax()
    max_value = standardized_industry_preference.iloc[i].max()
    plt.text(i, max_value + 0.01, f'{max_industry}', ha='center', va='bottom', fontsize=8, fontproperties=font)

plt.savefig('output\\graph\\standardized_industry_preference_by_group.png')
plt.show()

# 可视化每个组别的平均市值
plt.figure(figsize=(12, 8))
average_size.plot(kind='bar', color='skyblue')
plt.title('Average Market Cap by Group', fontproperties=font)
plt.xlabel('Group', fontproperties=font)
plt.ylabel('Average Market Cap', fontproperties=font)
plt.xticks(rotation=0)
plt.savefig('output\\graph\\average_market_cap_by_group.png')
plt.show()

# 可视化每个组别的平均收益率
plt.figure(figsize=(12, 8))
average_return.plot(kind='bar', color='skyblue')
plt.title('Average Monthly Return by Group', fontproperties=font)
plt.xlabel('Group', fontproperties=font)
plt.ylabel('Average Monthly Return', fontproperties=font)
plt.xticks(rotation=0)
plt.savefig('output\\graph\\average_monthly_return_by_group.png')
plt.show()

# 可视化每个组别的波动率
plt.figure(figsize=(12, 8))
volatility.plot(kind='bar', color='skyblue')
plt.title('Volatility by Group', fontproperties=font)
plt.xlabel('Group', fontproperties=font)
plt.ylabel('Volatility (Standard Deviation of Monthly Return)', fontproperties=font)
plt.xticks(rotation=0)
plt.savefig('output\\graph\\volatility_by_group.png')
plt.show()

#%% 使用米筐进行回测

config = {
    "base": {
        "accounts": {
            "STOCK": 100000,
        },
        "start_date": "20220101",
        "end_date": "20240930",
    },
    "mod": {
        "sys_analyser": {
            "plot": True,
            "benchmark": "000300.XSHG"
        }
    }
}


def read_tables_df():
    # need pandas version 0.21.0+
    df = pandas.read_csv(r'financial_data_with_return_predictions_rf_ret_PCA.csv')
    df['code'] = df['code'].astype(str).apply(lambda x: rqdatac.id_convert(x.zfill(6)) if ".OF" not in x else x)
    df['date'] = pd.to_datetime(df['date'])  # Ensure date is in datetime format
    print(df)
    return df


def on_order_failure(context, event):
    # Check if the event has the order attribute
    if hasattr(event, 'order'):
        order_book_id = event.order.order_book_id
        context.next_target_queue.append(order_book_id)
        print("[{}]下单失败，该标将于次日下单".format(order_book_id))
    else:
        print("Event does not have order attribute")


# 在这个方法中编写任何的初始化逻辑。context对象将会在你的算法策略的任何方法之间做传递。
def init(context):
    import rqalpha
    import rqalpha_mod_fund
    df = read_tables_df()  # 调仓权重文件
    context.target_weight = df
    context.adjust_days = set(context.target_weight.date.to_list())  # 需要调仓的日期
    print(context.adjust_days)
    context.target_queue = []  # 当日需要调仓标的队列
    print(context.target_weight)
    context.next_target_queue = []  # 次日需要调仓标的队列
    print(context.target_queue)
    subscribe_event(EVENT.ORDER_CREATION_REJECT, on_order_failure)
    subscribe_event(EVENT.ORDER_UNSOLICITED_UPDATE, on_order_failure)


# 每天策略交易开始前被调用，当天只会被调用一次
def before_trading(context):

    dt = context.now
    if dt in context.adjust_days:
        today_df = context.target_weight[(context.target_weight.date == dt) & (context.target_weight.label == -1)].set_index("code")
        context.target_queue = today_df.index.to_list()  # 更新需要调仓的队列
        context.next_target_queue.clear()
        # 非目标持仓 需要清空
        for i in context.portfolio.positions.keys():
            if i not in context.target_queue:
                # 非目标权重持仓 需要清空
                context.target_queue.insert(0, i)
    else:
        context.target_queue = []
        print("今日无调仓")


# 数据更新将会触发此段逻辑，例如日或分钟历史数据切片或者是实时数据切片更新
def handle_bar(context, bar_dict):
    if context.target_queue:
        for _ticker in context.target_queue:
            if rqdatac.is_suspended(_ticker).empty:
                logger.info(f"[{_ticker}]停牌，跳过")
                continue
            _target_weight = 0.01       # 等权持有100股
            logger.info(f"Placing order for {_ticker} with target weight {_target_weight}")
            o = order_target_percent(_ticker, round(_target_weight, 6))
            if o is None:
                logger.info(f"[{_ticker}]下单失败，该标将于次日下单")
                context.next_target_queue.append(_ticker)
            else:
                logger.info(f"[{_ticker}]下单成功，现下占比{round(_target_weight, 6) * 100}%")
        # 下单完成 下单失败的的在队列context.next_target_queue中
        context.target_queue.clear()


# 每天交易结束后被调用，当天只会被调用一次
def after_trading(context):
    if context.next_target_queue:
        context.target_queue += context.next_target_queue
        context.next_target_queue.clear()
    if context.target_queue:
        logger.info("未完成调仓的标的:{}".format(context.target_queue))


if __name__ == '__main__':
    from rqalpha_plus import run_func

    run_func(init=init, before_trading=before_trading, after_trading=after_trading, handle_bar=handle_bar,
             config=config)

```

* 大宗商品简单carry策略

```python
from rqalpha.apis import *
from rqalpha_plus import run_func
import rqdatac
import pandas as pd

config = {
    "base": {
        "accounts": {
            "future": 1000000,
        },
        "start_date": "20100101",
        "end_date": "20241231",
        "margin_multiplier": 1.05,
        "frequency": "1d",
        "futures_time_series_trading_parameters": True,
    },
    "mod": {
        "sys_analyser": {
            "plot": True,
            "benchmark": "000300.XSHG",
            "record": True,
            "strategy_name": "commodity_carry10_strategy",
            "report_save_path": "report_commodity_carry10_strategy.csv",
            "plot_save_file": "plot_commodity_carry10_strategy.png",
        },
        'sys_simulation': {
            'enabled': True,
            'matching_type': 'current_bar',
            'volume_limit': False,
            'volume_percent': 0,
            "slippage_model": "PriceRatioSlippage",
            "slippage": 0.0005,
        },
        "sys_progress": {
            "show": True,
        },
    }
}

def get_last_trading_days(trading_days):
    last_trading_days = []
    for i in range(1, len(trading_days)):
        if trading_days[i].month != trading_days[i-1].month:
            last_trading_days.append(trading_days[i-1])
    last_trading_days.append(trading_days[-1])
    return last_trading_days

# 初始化逻辑
def init(context):
    context.contracts = [
    "A", "AG", "AL", "AP", "AU", "BU", "C", "CF", "CU", "EB", "EG", "FG", "HC", "I", "J", "JM", "L", "LH", "M", "MA", 
    "ME", "NI", "OI", "P", "PG", "PP", "RB", "RM", "RO", "SA", "SC", "SF", "SN", "SR", "SS", "TA", "V", "Y", "ZN"
]
    context.trading_days = rqdatac.get_trading_dates("2010-01-01", "2024-09-30")
    context.last_trading_days = get_last_trading_days(context.trading_days)
    
# 交易开始前被调用，当天只会被调用一次
def before_trading(context):
    if context.now.date() in context.last_trading_days:
        logger.info("月度调仓开始")
        context.to_close_positions = list(context.portfolio.positions.keys())
    else:
        logger.info("非调仓日")

def handle_bar(context, bar_dict):
    # Close positions if it's the last trading day of the month
    if hasattr(context, 'to_close_positions'):
        for i in context.to_close_positions:
            if context.portfolio.positions[i].buy_quantity > 0:
                sell_close(i, context.portfolio.positions[i].buy_quantity)
                logger.info(f"{i} 空头平仓")
            if context.portfolio.positions[i].sell_quantity > 0:
                buy_close(i, context.portfolio.positions[i].sell_quantity)
                logger.info(f"{i} 多头平仓")
        del context.to_close_positions

    if context.now.date() in context.last_trading_days:

        # 获取当前主力合约
        dominant_contracts = []
        second_dominant_contracts = []
        for i in context.contracts:
            dominant_contract = rqdatac.futures.get_dominant(i, context.now, rule=0)
            second_dominant_contract = rqdatac.futures.get_dominant(i, context.now, rule=0, rank=2)
            if dominant_contract is not None and not dominant_contract.empty:
                dominant_contracts.append(dominant_contract.iloc[0])
            if second_dominant_contract is not None and not second_dominant_contract.empty:
                second_dominant_contracts.append(second_dominant_contract.iloc[0])
        print(dominant_contracts)
        print(second_dominant_contracts)

        # 获取当前交易日前十个交易日的历史数据
        start_date = context.trading_days[max(0, context.trading_days.index(context.now.date()) - 9)]
        dominant_contract_price_df = rqdatac.get_price(dominant_contracts, start_date=start_date, end_date=context.now, frequency='1d', fields=['settlement'], adjust_type='pre', skip_suspended=False, market='cn', expect_df=True, time_slice=None)
        second_dominant_contract_price_df = rqdatac.get_price(second_dominant_contracts, start_date=start_date, end_date=context.now, frequency='1d', fields=['settlement'], adjust_type='pre', skip_suspended=False, market='cn', expect_df=True, time_slice=None)

        # 获取主力合约的到期日
        dominant_contract_info = rqdatac.instruments(dominant_contracts, market='cn')
        dominant_contract_maturity_dates = [(contract.order_book_id, contract.maturity_date) for contract in dominant_contract_info]
        print(dominant_contract_maturity_dates)

        second_dominant_contract_info = rqdatac.instruments(second_dominant_contracts, market='cn')
        second_dominant_contract_maturity_dates = [(contract.order_book_id, contract.maturity_date) for contract in second_dominant_contract_info]
        print(second_dominant_contract_maturity_dates)

        # 提取月份
        dominant_maturity_months = {contract: pd.to_datetime(maturity_date).month for contract, maturity_date in dominant_contract_maturity_dates}
        second_dominant_maturity_months = {contract: pd.to_datetime(maturity_date).month for contract, maturity_date in second_dominant_contract_maturity_dates}
        print(dominant_maturity_months)

        # 计算每个合约的十天平均carry
        average_carry_list = []
        for dominant, second_dominant in zip(dominant_contracts, second_dominant_contracts):
            dominant_prices = dominant_contract_price_df.loc[dominant]['settlement'].values
            second_dominant_prices = second_dominant_contract_price_df.loc[second_dominant]['settlement'].values
            dominant_maturity_month = dominant_maturity_months[dominant]
            secondary_dominant_maturity_month = second_dominant_maturity_months[second_dominant]

            # Ensure both arrays have the same length
            min_length = min(len(dominant_prices), len(second_dominant_prices))
            dominant_prices = dominant_prices[-min_length:]
            second_dominant_prices = second_dominant_prices[-min_length:]

            carry = (dominant_prices - second_dominant_prices) / (second_dominant_prices * (dominant_maturity_month - secondary_dominant_maturity_month))
            average_carry = carry.mean()
            average_carry_list.append((dominant, average_carry))
            print(f"Average Carry for {dominant} and {second_dominant}: {average_carry}")

        # 对所有合约的十天平均carry排序，从小到大分为5档
        average_carry_list.sort(key=lambda x: x[1])
        num_groups = 5
        group_size = len(average_carry_list) // num_groups
        carry_groups = [average_carry_list[i * group_size:(i + 1) * group_size] for i in range(num_groups)]

        # 根据carry策略进行交易
        for group_index, group in enumerate(carry_groups):
            for dominant, average_carry in group:
                if average_carry > 0 and group_index == 4:
                    # 做空主力合约
                    if context.portfolio.positions[dominant].buy_quantity > 0:
                        sell_close(dominant, context.portfolio.positions[dominant].buy_quantity)
                    sell_open(dominant, 1)
                    logger.info(f"{dominant} 空头开仓")
                elif average_carry < 0 and group_index == 0:
                    # 做多主力合约
                    if context.portfolio.positions[dominant].sell_quantity > 0:
                        buy_close(dominant, context.portfolio.positions[dominant].sell_quantity)
                    buy_open(dominant, 1)
                    logger.info(f"{dominant} 多头开仓")

        print("Average Carry List:", average_carry_list)

if __name__ == '__main__':
    from rqalpha_plus import run_func

    run_func(init=init, before_trading=before_trading, handle_bar=handle_bar, config=config)

```

---
### 语言能力

---
### 